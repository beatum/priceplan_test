{% extends 'base.html' %}
{% load static %}

{% block content %}
    <p class="font-weight-bold">1) Напишите view на django, которая в начале выполняет первую запись в бд. Потом выполняет вторую и с вероятностью в 20% генерирует ошибку в конце из-за чего вторая запись не должна быть сохранена.</p>
    <p>Для проверки результата выполните команду <code>./manage.py run_view</code></p>
    <p>Код и комментарий в фаиле <code>projects/apps/interpoints/management/commands/run_view.py</code></p>
    <p class="font-weight-bold">2) Как бы Вы реализовали критическую секцию на python?</p>
    <p>Риторический вопрос! Ответ зависит от массы факторов. Но в целом посмотрел бы в сторону алгоритмов Деккера, Петерсона или Лампорта.</p>
    <p class="font-weight-bold">3) У Вас есть крутой проект на Django, который крутится на 10 серверах. Как реализовать на уровне PostgreSQL логику, при которой ни один из параллельных процессов не может изменять строчку в бд, пока не закроет транзакцию первый процесс.</p>
    <p>Предворительно, изучив наиболее типичные реализации (NAS, DRBD, Потоковая репликация, Slony, pgpool-II, Bucardo), с помощю которых сегодня осуществляется масштабирование, я склонился в сторону Slony или Bucardo. Оба решения, работают по принципу асинхронной репликации.</p>
    <p>При асинхронной репликации в Slony (главный-резервный на основе триггеров) или Bucardo (репликация с несколькими главными серверами) все запросы, изменяющие данные, пересылаются главному серверу или группе главных серверов. Главный сервер(а), в свою очередь выполняют соответсвующие транзакции изменяющие данные, а затем асинхронно пересылает изменённые данные резервным серверам.</p>
    <p>Резервные сервера могут обрабатывать запросы только на чтение при работающем главном. Такой подход является наиболее подходящим для обработки запросов и хранения данных в различных хранилищах.</p>
    <p>Основной недостаток в том, что обновление на резервных серверах происходят асинхронно (в пакетах), поэтому возможны потери данных во время отказа главного сервера, но пологаю, возможно есть решения и на этот случай.</p>
    <p>Для того, чтобы более детально ответить на поставленный вопрос, нужно понимать, каким образом организована архитектура масштабирования. Чисто логически можно предположить, что в момент отправки запросов к базе мы можем применить возможности управления конкурентным доступом, а именно изолировать транзакции на уровне конфигурации СУБД (к примеру возьмём, PostgreSQL): Можно выбрать уровень изоляции Serializable - он обеспечивает самую строгую изоляцию транзакций. На этом уровне моделируется последовательное выполнение всех зафиксированных транзакций, как если бы транзакции выполнялись одна за другой, последовательно, а не параллельно. Ну и соответсвенно для частичной гарантии можно применить предиктовые (pg_locks) или явные блокировки.</p>
    <p>Когда возможны несериализуемые (ошибочные) операции записи, для обеспечения целостности строк и защиты от одновременных изменений, следует использовать <code>SELECT FOR UPDATE, SELECT FOR SHARE</code> или соответствующий оператор <code>LOCK TABLE</code>. (<code>SELECT FOR UPDATE</code> и <code>SELECT FOR SHARE</code> защищают от параллельных изменений только возвращаемые строки, тогда как <code>LOCK TABLE</code> блокирует всю таблицу - обеспечивая изолированное выполнение транзакции).</p>
    <p>P.S. Признаемся честно! Сила любой CУБД в атомарном параллелизме, а не в линейных транзакциях с блокировками, хотя это всего лишь моё скромное предположение!</p>
    <p class="font-weight-bold">4) Вы работаете на режимном предприятии, где каждый день все сотрудники обязаны выполнять одинаковую последовательность задач и отмечать это на компьютере (как в сериале Lost)</p>
    <p><span class="font-weight-bold">4.1)</span> Напишите django приложение, которое генерировало бы для каждого сотрудника его список задач на сегодня. И небольшой интерфейс, в котором сотрудник видел этот список задач в строгой последовательности. И отмечал выполненное, при этом он не мог бы перейти к следующей задаче, пока не выполнить предыдущее. Каждый день список сбрасывается.</p>
    <p><a href="/todo/">Страница результата: Управление задачами</a> - но прежде, внимательно прочтите README.md</p>
    <p>Доступные команды:</p>
    <ul>
      <li><code>./manage.py make_task</code> - создать задачи для всех сотрудников</li>
      <li><code>./manage.py clear_task</code> - отправить все задачи в историю</li>
      <li><code>./manage.py run_sheduler</code> - создать задачи для всех сотрудников и запустить планировщик-чистильщик (прежде, чем выполнить эту команду, вам необходимо запустить два сервиса: <code>rqscheduler -i 5 && ./manage.py rqworker</code> - в корне проекта, в отдельном окне</li>
    </ul>
    <p>Задачи можно переопределить в фаиле <code>.../project/apps/interpoint/management/commands/make_task.py</code></p>
    <p>Работу планировщика можно переопределить в фаиле <code>.../project/apps/interpoint/management/commands/run_sheduler.py</code></p>
    <p><span class="font-weight-bold">4.2)</span> Напишите (запрос через ORM )<p>
    <ul>
      <li>список выполненных задач за определенный день</li>
      <li>число всех выполненных задач за определенный день</li>
      <li>список выполненных задач определенного сотрудника (имя задачи, время, имя сотрудника)</li>
      <li>список невыполненных задач определенного сотрудника за любой день</li>
    </ul>
    <p><a href="/request/">Страница результата: Запросы к ORM</a></p>
{% endblock %}
